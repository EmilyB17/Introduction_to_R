---
title: "Introduction to R"
subtitle: "Written by Gordon Custer 2018"
output: html_notebook
---
#Introduction
For many of you this may be your first experience with R. The goal of this module is to familiarize you with the basics of R and R Studio. In the processes we hope that this tutorial will help you overcome the anxiety that exists when trying to learn something new. First off, what is R? R is both a programming language and software environment for statistical computing and easy visualization. The benefit of R versus some other statistical computing software packages is that R is totally free and can be downloaded to any computer. This means if you are working for the forest service in a small office in the middle of nowhere, you don't have to convince your boss to purchase a $10,000 subscription of SPSS. R is available for free! In addition, many add-ons (packages) exist which can make for easy data manipulation, statistical testing and visualizaiton. As for R studio, R studio offers a GUI (Graphical User Interface) with drop down menus, and handy visualizations of key features. R does the work; R studio makes it pretty. 

#Getting Started
After opening R studio you will see 4 panes (maybe 3, meaning one is hidden and we can fix that here in a minute). These four panes are as follows and their locations are given based upon the defaults of R Studio. You can change this if you prefer an alternate set up. 
      1. Source (Top Left). This pane contains the scripts you are working on currently. You can have more than one open at a time.
      2. Console (Bottom Left). This pane contains a history of the commands you have ran. You can also code directly in this pane, though not always recommended. 
      3. Environment/History/Connections (Top Right). The environment contains data which R can access at this given moment. The history tab contains a history of the code you have ran. The connections tab allows you to access outside data sources.
      4. The final pane (Bottom Left) contains several tabs. In this pane, you can view plots, search for files on your computer, install packages (we will get to this in a minute), and even find documentation on packages or functions. This pane is your friend. Become comfortable with it and you will use it often. 
      
#Opening a script and saving
Any experienced R user will tell you one of the benefits of using a program, such as R, is the ability to write code once and "reuse" it over and over again with slight modifications. This allows you to run an analysis for a collaborator (or yourself) and save it until next year when they ask you to do the same thing again. As mentioned above, you could type directly into the console, but this would only save your work until you exit the program. In order to save your work for future analyses, programming into a notebook or script is highly recommended. For example, this R script is written in a special kind of notebook known as markdown. This format, which is different from an R script, allows programmers to include text, figures, headings, and code all in the same place which makes for easy distribution. In addition, this notebook can be rendered in a .html format so anyone with a web-browser can access it. On the other hand, the simplest way to keep a copy of your program or code is to use the R-script option. There are several other options as well but for the sake of simplicity we will only look at these two. For your first task, lets further explore the two options discussed above. 

This is your first exercise. You can read the quesiton here and write your answer in the Word doc "Introduction_to_R_worksheet". You'll notice that as you type and enter new information to your Rnotebook line numbers shift. We have tried to account for entering new lines and based approximate line number off of that. However, in some cases the line numbers may not match up. Keep that in mind when you are looking for an exercise. 

Exercise 1: Navigate to the "File" drop down menu in the toolbar. Click "New File", and open first a "R Script" and then open a "R Notebook". What do you notice about initial appearances? Answer this question in the lab handout. Go to the R Notebook, and run the default script that is displayed in the greyed-out area by clicking on the green triangle in the top right corner of the greyed-out area. The code displayed at the beginning ```{r} and at the end ``` is just used to indicate the start and end of the R code in the R Notebook, and should not be copied into the R script. Copy and past the code (only "plot(cars)") into the basic R Script file you just created and run the script by highlighting the command (plot(cars)) and pressing *Cmd+Enter* (or *Control+Enter on Windows). What is different between the two file type with respect to where the figure appears? Answer this question in the labhandout.

Now, lets see what a co-worker would see if you supplied them a copy of your R Notebook in .html format. Go back to your R notebook you just created, currently titled "Untitled2". On the top of the "Source" pane (top left pane), there is a small button "R Preview". Make sure you have run the plot(cars) command and the figure shows up. Then, click this preview option. You will likely have to install a necessary pacakges. We will cover how to do this in more detail in the following section. However, for now follow the instructions provided in the pop-up window. After you have installed the necessary packages, the preview option will prompt you to save this script. Save it in your "Introduction_to_R_YOURLASTNAME" folder on the Desktop. It is good practice to save scripts with a descriptive name so you can find it easily at a later date; name this file "ScriptTest_Rnotebook". Once the notebook has rendered, open the .html file from your Finder (or Search) window, and you will see the plot(cars) graph embedded in the document. In addition, you can show or hide the code which was used to produce this graph by clicking "hide" button to the right of the R code blocks. While this example is very simple, the same holds true for more complex analysis. 

#Installing a package
Before we get into data manipulation let's quickly go over how to install a package and load it in your current session. Simply put, a package is a collection of programs or functions which might not be included in basic install of R. The default installation and tools included are also known as base R. Installation of packages allows for users to access functions and run analyses without having to write all of the code themselves. The data set used below actually comes included in the "MASS" package. In order to load a package, you must first install it. You only need to install a package once, but you may have to load it many times (usually everytime you start a new session). Below you will find two lines which will help you install any given package. Notice the quotations around the name of the package MASS; without them the function will not work. Run the script below (remember the green triangle button) to install the MASS package. Check your console pane at bottom left, as you may get the following message:
"Do you want to install from sources the packages which need compilation? y/n:"
If so, type y (for yes) and press enter to continue the installation.
 

```{r}
#this line downloads the package to your machine
install.packages("MASS")
#this line loads the package into your current session
require(MASS)
#this lets you see what packages you have loaded at the moment
(.packages())
```

While this package loaded relatively quickly some packages take hours to successfully download and install and may requires many dependencies to run successfully.  

Exercise 2: Find the 'lubridate' package by going to the "packages" tab in the bottom right pane. Click on "Install"" and search for 'lubridate' in the search bar named "packages". Make sure that the "Install dependencies" box is checked, and click "Install". Again, type 'y' if you get the following message in your console pane: "Do you want to install from sources the packages which need compilation? y/n:". Explore some of the functions included in the 'lubridate' package. To do so, go to the "Packages" tab in the bottom right pane, and in the search bar type 'lubridate'. The package name should come up in the list. Click on the name of the package. This is also a link to the help page. What can you do with this package? Answer this question in the labhandout.

A tip that will come in handy nearly every time you are using R is that you can always Google your problem!! We will get into this in more detail here shortly. But for now, if you ran "install.packages("DADA2")" nothing would install. That is because the DADA2 package isn't available on the CRAN repository, where packages are normally found. This package is available through Bioconductor. Many packages (>1500) which are extremely useful for data analysis are found on Bioconductor. This is a great example of the flexibility of R. Below is a link to the installation guide for DADA2. Look at the link below for a detailed walk through on the installation of DADA2. You will not need to install this but it is worth knowning that alternate pathways exist for installation of needed packages.

https://benjjneb.github.io/dada2/dada-installation.html


#Familiarizing yourself with your working environment. 
Your working environment and working directory are extremely important when you want to read in data or save an analysis. Imagine you are in your office; this is your working directory. You can write on a piece of paper and save it on your desk. You can also find notes which you left yourself. You are able to easily access anything in your office. Your neighbors office, while located in the same hallway, requires you to back out of your office and then enter hers. This analogy holds true for finding files on your computer as well. Your working environment will allow you to access files quickly and to write copies of your analysis or environment easily. Like you can walk into your co-workers office, you can change your working directory to access a different set of files. 

As an example, lets use the file named "pima.csv". We have already loaded this to the folder on the desktop which you have renamed to "Introduction_to_R_YOURLASTNAME". 

Our goal in this section is to read in the file 'pima.csv' sucessfully as well as see what happens when we specify the wrong location. Doing so will help you to understand you can learn from coding errors. Up until now all text has been written outside of a block of code. In order to add comments, which is a really good, I mean REALLY good, habit to get into, you only need to add a "#" before any line you do not wish R to interpret. In the code below (lines ~60-67) you can see certain lines are not interpreted even if you ran the block as a whole. These comments will not show up in your rendered .html notebook either. You have to open the notebook in R studio to access these comments. 

Here (lines 60-67) we have a block of code, also referred to as a "chunk". Anything in here can be ran by clicking the green triangle button in the top right corner of the block. In addition, we can # out this block by placing a "#" before the r in the ```{r}. The keyboard shortcut for inserting a new block of code is "Command" + "Option" + "i". Run both sections of code below by clicking the green triangle button. 

```{r}
#R will not interpret this line due to the # at the begining
#Lets see where we are right now (our current working directory)
getwd()
```

```{r}
#Now lets say we want to change our working directory to your desktop folder on your machine. This will only change the working directory in this chunk of code. Once this chunk finishes running your working directory will revert to whatever it was prior to running this chunk. 
setwd("/Users/ursus03/Desktop/ECOL5540")
``` 
You will get an error message 'cannot change working directory'. It is because the pathway you specified doesn't exist on your computer. 

Exercise 3: Insert a new chunk below. Then, write the correct code to change the working directory to your folder on the Desktop of your computer that your created at the beginning of lab, and write the code to get what your current directory is. Run the whole code and copy the whole code you created to the exercise 3 location in your lab handout. 

#Loading data
Now lets try to read in our data (pima.csv). In order to do so, we need to make sure we are in the correct working directory and the file exists. You can do this by making sure the folder on your desktop contains the pima.csv file.

Below are two lines of code which read in the data set. However, there is one slight difference. Run the block "code 1" first, then run "code 2".
```{r}
#Code 1
setwd("/Users/ursus03/Desktop/GordonClass/")
read.csv("Pima.csv")
```
Code 2 
```{r}
#Code 2
setwd("/Users/ursus03/Desktop/GordonClass/")
Pima<-read.csv("Pima.csv")
```
Exercise 4: What is the difference between the two blocks and what does it do? Hint: Look in your environment. Answer this question in the lab handout. Next, run the code below (lines 89-91). What happened when you forget to include the "" around the file name? Answer this question in the labhandout. Next, run the code below. What happens when your working directory is changed back to the "Downloads" folder? Answer this question in the labhandout.

```{r}
setwd("/Users/ursus03/Desktop/GordonClass/")
Pima<-read.csv(Pima.csv)
```

```{r}
setwd("/Users/gordoncuster/Downloads/")
Pima<-read.csv("Pima.csv")
```
Exercise 5: A final consideration for reading files in is to specify the entire path to the file. This is often the safest way to operate because it doesn't matter where your working directory is set. By doing so, you can find a file no matter where it is on your computer. Run the code below (lines 98-100), which is an example of how to specify the entire pathway to a file on my desktop. Copy the error message to your lab handout in the exercise 5 answer slot. 
```{r}
Pima<-read.csv("/Users/gordoncuster/Desktop/pima.csv")
```
Next, insert a new chunk below and write the correct code to read in the Pima.csv file using the entire pathway to your folder on your Desktop. Run the code to see if there are no error messages and then copy the code to your lab handout in the exercise 5 location. 

Disclamier: R will yell at you. Get used to it. It happens all the time. Learn to embrace it and you will be well on your way to solving any problem R can throw at you. Did you notice that the symbol "<-" saves whatever is to the right as a variable named what you have to the left of the symbol "<-". This can be extremely useful when selecting a subset of a data frame or running an analysis. You don't want to have to re-run it every time. By saving it to a new variable you can access it whenever you wish. 

Tip: Help pages. Under the "Help" tab in the bottom right pane, type "read.csv" in the search bar with the magnifying glass. This page will tell you everything that the function read.csv (well actually read.table) requires and can do. Become familiar with these pages and you can avoid many headaches. Each page provides a brief description of the function, the usages, required arguments, outputs (values), and a short example snippet of code.

Exercise 6: Copy the description, that appeared in your help pane after you searched for "read.csv", to your lab handout in the exercise 6 answer slot. 

Now that our data is read in, lets see what it looks like. We can do this several ways. Below are several ways to look at the data. Look at each of the different types of data display by running the code blocks below.  
```{r}
#Code 1, just the name of the data file, will give you an overview of what the data looks like for all your columns.
Pima
```

```{r}
#Code 2: the word 'str' in this code will display the structure of the data; data type, number of observations and variables and variable type
str(Pima)
```

```{r}
#Code 3 will give you a summary of the data, with min, median, max values of each variable.
summary(Pima)
```

Exercise 7: Look at the output from str(Pima). The data structure of Pima is a data.frame. What other types exist? Use Google and look for other data types. Answer this question in the labhandout. The type of data is an important point because some functions in R require a certain type of data. Usually, this will be pointed out on the functions help page. 

What if you need another type of data? Some functions which are extremely useful for converting among data types are data.frame and as.matrix. 
Exercise 8: Convert the Pima data.frame to a matrix, using the code below, and then check its structure. Copy the info displayed of the structure to your lab handout in the exercise 8 location. Once you have done this convert the Pima matrix back to a data.frame, using the second code below. 

```{r}
#The code as.matrix will convert your dataframe to a matrix
Pima<-as.matrix(Pima)
str(Pima)
```

```{r}
#The code as.data.frame will convert your matrix back to a data frame again 
Pima<-data.frame(Pima)
Pima$test<-as.factor(Pima$test)

str(Pima)
```
After you have converted the Pima matrix back to a data.frame check its structure again. You will see that each variable has a data type associated with it. In our Pima data.frame we have 8 numeric (num) and 1 factor (factor). What do some of these things mean (character vs. numeric vs. factor)? Numeric and integers are ways of encoding numeric data. The big difference is that integers can not have decimals while numeric variables can. Factors are a good way of including categorical data. As you can see the test column is a factor with two levels. The levels correspond to a positive or negative test for diabetes, with 1 being positive and 0 negative.

#Working with data
In the code below we introduce an easy way to pull out a single column from a data set. Run the coode below and take a look at the resulting figures. As you will see, the "$" operator allow you to select a single column. 
```{r}
# The first line of code will display all variables in various plots, the second line will plot only the diastolic variable, and the third code line will result in a histogram of the variable diastolic.
plot(Pima)
plot(Pima$diastolic)
hist(Pima$diastolic)
```
Exercise 9: Suppose you wanted to select several columns. Let's say columns 1-5. What would you do? Let's use this opportunity to try and Google your problem. This is another useful skill to master. If you can put your problem in the correct terms, it is very likely someone else has faced the same difficulty and will be able to help.  Search Google for the answer to this problem. I would say start Googling something like "Program R select multiple columns" or "subset data frame to only include certain columns Program R". As you can see from these two suggestions, the exact verbiage isn't that important. Copy your final code to your lab handout in the exercise 9 answer slot, as well as the first line of the resulting display of the data structure using the 'str' command.
```{r}
#Type your code in the next line that will create a subset of the data set with just columns 1 through 5 selected. Then run the full code, and by using str(subset_Pima), you can check if you did correctly selected the 5 columns.
str(subset_Pima)
```
Hopefully you found out that the square brackets work such that numbers before the comma indicate rows (by leaving this blank we are telling the program we want all rows) and numbers occurring after the comma indicate columns. Above, we are saying we want only columns 1:5. The c() concatenates this selection. We could also include columns that are not next to each other by writing our brackets to look something like this [,c(1:4, 7)]. This would only select columns 1, 2, 3, 4, and 7. 

Another way to do this would be to make a vector of the column names you wish to keep. Let's use the following block to walk through these steps. Here we introduce a new function, unique. The unique function runs through what ever the input may be and prints each unique value present in the vector or data frame. This function can be very useful. 
```{r}
unique(colnames(Pima))
#you could also do this by using the names() function
#Let's now only pull out the columns "glucose", "diabetes", and "bmi". In order to do so lets make a vector containing these values.
columns_to_keep<-c("glucose", "diabetes","bmi")
subset_Pima<-Pima[,colnames(Pima) %in% columns_to_keep]
str(subset_Pima)
```
Exercise 10: Can you interpret what is going on in the "subset_Pima<-Pima[,colnames(Pima) %in% columns_to_keep]" line of code? Try to put it into plain English. Hint %in% reads as "found in". 

Exercise 11: Insert a new chunk of code (don't remember how do do this, see line 58) and write a code that will pull only the first two rows of the columns "age" and "triceps". Copy your final code to your lab handout in the exercise 11 location.

Something to keep in mind is that there are several ways to accomplish the same feat. As of now we have used base R to subset data. A very valuable suite of tools in R come in the Tidyverse package. We will very breifly introduce the Tidyverse but a more detailed introduction and exaplnation can be found online. 

Install the tidyverse package and load it for use. The chunck below only includes the code to load the package (library(tidyverse)). Can't remember how to install a package, see lines 29-36.
```{r}
#type necessary code to install the tidyverse package
require(tidyverse)
```

Some very useful functions available through the tidyverse package are filter, select, mutate, group_by, gather, join, summarize, and spread. Also available through the tidyverse is the "%>%". This symbol is called a pipe. The pipe allows you to string together functions instead of breaking them up into individual lines of code. Below is an example of how to run a line individually and then an example of how to string together tidyverse functions using the pipe symbol.

```{r}
#Suppose you wanted to keep all subjects with a glucose level under 100. You could use the fliter funciton
filter(Pima, glucose <= 100)
#Now suppose you wanted to get the mean blood glucose value for individuals with diabetes and individuals without diabetes. 
Pima %>%
  group_by(test) %>%
  summarize(mean_glucose = mean(glucose, na.rm = TRUE))
```
Exercise 12: Filter pima to only include the individuals that are over 25. Then get the average B.M.I. for both the positive and negative test groups. Copy your final code to your lab handout in the exercise 12 location.

Answer:
```{r}
#This will be removed 
Pima %>%
  filter(age > 25) %>%
  group_by(test) %>%
  summarize(avg_BMI = mean(bmi, na.rm = TRUE)) 
  

```
The tidyverse offers a wide array of functions that can make your life easier. It would be wise to familiarize yourself with these functions and make use of them in the future. The tidyverse offers a large number of packages and would prove too much to cover today. This was included to show that many methods exist for manipulating data. 

##Here is where the final activity could be customized for a given class
some examples include: make a histogram
plot some data
run an Anova/t.test

This section below was developed for Linda's microbial diversity and ecology course. 

Before we call it quits today, let's take this opportunity to practice with some data manipulation in R. In a couple weeks or so you will be analyzing data collected by a student for their Master's project. In order to determine the effect of treatment we need to make sure we assign the correct data to the correct sample. To accomplish this we want to create a metadata sheet. A metadata sheet will contain all the data collected about each sample. Provided to you is a copy of the excel sheet "Metadata.csv". This sheet contains the site's ID, pH, EC, water content, enzyme values, and C:N. From the name we want to extract the other important information and include this in the metadata in a more explicit form. For example, the site name H11B actually means, the sample was collected from a healthy stand (H), it is the first sampling time (1), site 1 of 5 for healthy stands (1), and it is the bulk soil component (B). In this section we will examine how to pull out data and make our own metadata sheet for further analysis.

Exercise 13: You have the Metadata.csv sheet in your class desktop folder. Next, read it into R (don't remember how, go back to line 74). Copy the code you used to load the data to your lab handout in the exercise 13 location.

First we need to create a column named Soil. This column will tell us whether the sample was collected from the bulk or rhizosphere component. 
```{r}
#look up the command substr() in the seach bar of the help tab in bottom right pane for more info on this command. Using the command below, you will create a new column named Soil (metadata$Soil) at the end of your current dataset metadata. The column will be created based on the 4th character (start = 4, stop = 4) of the values in your Sample_ID column (metadata$Sample_ID). 
metadata$Soil<-substr(metadata$Sample_ID, start = 4, stop = 4)
#Using the code below you can check to see if the column Soil was added, and what the values are, which should be either A or B.
metadata
```

```{r}
#Next, we create and index with the values currenty in the column; A and B
index <- c("A", "B")
#Then we identify the values that we wish to insert in the place of the "index", which are Rhizosphere for A and Bulk for B.
values <- c("Rhizosphere", "Bulk")
metadata$Soil<- values[match(metadata$Soil, index)]
#And again, we can check to see if the column Soil was added, and what the values are now, which should be either Rhizosphere or Bulk.
metadata
```

Exercise 14: Create a column called "Infestation_Stage". This is designated by the first character in the Sample_ID. H means the sample was collected from a healthy stand, I from an infested stand, and D from a dead stand. In the newly created column "Infestation_Stage" the letter pulled from the first character of the Sample_ID should then be replaced with "Healthy", "Infested", or "Dead". Use the code in the previous sections above (lines 216-231) as a template for writing this new code. 
Copy the full code you used to your lab handout in the exercise 14 location.
Answer:
```{r}
```

Lets look at our newly minted metadata sheet.
```{r}
View(metadata)
```

Exercise 15: Save your new metadata file as a .csv to your desktop folder. Save it as a new file from the one your downloaded, i.e. change the name. Copy the full code you used to your lab handout in the exercise 15 location.
```{r}
#code to use to write the new metadata file to your folder on the Desktop, remember, change the path to the file so that it will be saved in the correct folder on your Desktop
write.csv(metadata,"/Users/LvanDiepen/Documents/teaching/Microbial div & ecology/2018/labs/HTS/Micro_Div-master/metadata_final.csv")
```

Lastly, suppose you are working with a huge data set. For many of you this will be the case. In order to avoid having to read in your data each and running time consuming code each and every time we can save your environment and reload it when you want to come back. To do so, look in the upper right pane under the environment tab. The save icon here will save your environment. 

Exercise 16: Save your working environment for use at a later date. Empty your environment by clicking on the "broom" symbol in the upper right pane under the environment tab and reload your saved data to make sure you are comfortable with this skill. For Reloading: click the "open folder" symbol in the upper right pane under the environment tab.

Citations and Resources:
1: https://www.r-project.org/ 
2: https://benjjneb.github.io/dada2/index.html
3. https://www.bioconductor.org/